{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mltools as ml\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irisXt = np.genfromtxt(\"data/X_train.txt\",delimiter=None)\n",
    "irisYt = np.genfromtxt(\"data/Y_train.txt\",delimiter=None)\n",
    "irisXv = np.genfromtxt(\"data/X_test.txt\",delimiter=None)\n",
    "\n",
    "Xtr,Ytr = irisXt,irisYt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "\n",
    "class randomForest(ml.base.classifier):\n",
    "\n",
    "    def __init__(self, learners):\n",
    "        self.learners=learners\n",
    "        self.classes=learners[0].classes\n",
    "\n",
    "    def predictSoft(self,X):\n",
    "        ysoft = np.zeros((X.shape[0],len(self.classes)));\n",
    "        for i in range(len(self.learners)): ysoft+=self.learners[i].predictSoft(X);\n",
    "        return ysoft/len(self.learners);\n",
    "\n",
    "#*********************\n",
    "# Initialize Learner *\n",
    "#*********************\n",
    "\n",
    "numEnsemble = 500\n",
    "ensemble = [ None ] * numEnsemble\n",
    "for j in range(numEnsemble):\n",
    "    Xb,Yb = ml.bootstrapData(Xtr,Ytr, n_boot=66000)\n",
    "    ensemble[j] = ml.dtree.treeClassify(Xb, Yb, maxDepth=50, minLeaf=4, nFeatures=4)\n",
    "\n",
    "    \n",
    "rf = randomForest(ensemble)\n",
    "# rfAUC = rf.auc(Xva, Yva) - 0.02\n",
    "# print(rfAUC)\n",
    "\n",
    "#******************\n",
    "# Make Prediction *\n",
    "#******************\n",
    "yPredictRF = rf.predictSoft(irisXv)[:, 1]\n",
    "\n",
    "np.savetxt('Yhat_dtree_bags.txt',\n",
    "np.vstack( (np.arange(len(yPredictRF)) , yPredictRF) ).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',');\n",
    "print(\"Finish Saving Random Forest Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Gradeint Boosting\")\n",
    "\n",
    "#*********************\n",
    "# Initialize Learner *\n",
    "#*********************\n",
    "\n",
    "learner = GradientBoostingClassifier(learning_rate=0.02, n_estimators=3000, max_depth=9, min_samples_leaf=32, max_features=\"log2\" )\n",
    "\n",
    "learner.fit(Xtr, Ytr)\n",
    "\n",
    "# gbAUC = learner.score(Xva, Yva)\n",
    "# print(gbAUC)\n",
    "#******************\n",
    "# Make Prediction *\n",
    "#******************\n",
    "\n",
    "yPredictGB = learner.predict_proba(irisXv)[:,1]\n",
    "\n",
    "np.savetxt('Yhat_gradient_boost.txt',\n",
    "np.vstack( (np.arange(len(yPredictGB)) , yPredictGB) ).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',');\n",
    "print(\"Finish Saving Gradient Boost Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"AdaBoost\")\n",
    "\n",
    "#*********************\n",
    "# Initialize Learner *\n",
    "#*********************\n",
    "\n",
    "learner =  AdaBoostClassifier(n_estimators=2500, learning_rate = 0.005, algorithm='SAMME.R',\n",
    "                              base_estimator=DecisionTreeClassifier(max_depth=12, min_samples_leaf=8, max_features=\"log2\"))\n",
    "\n",
    "learner.fit(Xtr, Ytr)\n",
    "\n",
    "# abAUC = learner.score(Xva, Yva)\n",
    "# print(abAUC)\n",
    "\n",
    "#******************\n",
    "# Make Prediction *\n",
    "#******************\n",
    "yPredictAB = learner.predict_proba(irisXv)[:,1]\n",
    "\n",
    "np.savetxt('Yhat_adaboost.txt',\n",
    "np.vstack( (np.arange(len(yPredictAB)) , yPredictAB) ).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',');\n",
    "print(\"Finish Saving adaBoost Result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yPredict = 0.2 * yPredictRF + 0.8 * yPredictGB\n",
    "np.savetxt('Yhat_final.txt',\n",
    "np.vstack( (np.arange(len(yPredict)) , yPredict) ).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',');\n",
    "print(\"Finish Saving final Result\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
